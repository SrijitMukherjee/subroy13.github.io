<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.6.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Subhrajyoty Roy">

  
  
  
    
  
  <meta name="description" content="This is post containing a very basic introduction to image segmentation. Here I discuss about gray level thresholding, Otsu&#39;s method and Gray level thresholding using Co-occurence matrix">

  
  <link rel="alternate" hreflang="en-us" href="/post/post5/">

  


  
  
  
  <meta name="theme-color" content="#222222">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/atom-one-dark-reasonable.min.css" crossorigin="anonymous" title="hl-light">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/atom-one-dark-reasonable.min.css" crossorigin="anonymous" title="hl-dark" disabled>
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather%7CLobster%7CLora%7CUbuntu+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/post5/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Subhrajyoty Roy">
  <meta property="og:url" content="/post/post5/">
  <meta property="og:title" content="An Introduction to Image Segmentation Techniques | Subhrajyoty Roy">
  <meta property="og:description" content="This is post containing a very basic introduction to image segmentation. Here I discuss about gray level thresholding, Otsu&#39;s method and Gray level thresholding using Co-occurence matrix"><meta property="og:image" content="/post/post5/featured.png">
  <meta property="twitter:image" content="/post/post5/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-03-23T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-03-23T00:00:00&#43;00:00">
  

  


    






  






<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/post5/"
  },
  "headline": "An Introduction to Image Segmentation Techniques",
  
  "image": [
    "/post/post5/featured.png"
  ],
  
  "datePublished": "2020-03-23T00:00:00Z",
  "dateModified": "2020-03-23T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Subhrajyoty Roy"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Subhrajyoty Roy",
    "logo": {
      "@type": "ImageObject",
      "url": "/img/icon-512.png"
    }
  },
  "description": "This is post containing a very basic introduction to image segmentation. Here I discuss about gray level thresholding, Otsu's method and Gray level thresholding using Co-occurence matrix"
}
</script>

  

  


  


  





<script data-ad-client="ca-pub-8206710020783397" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

  <title>An Introduction to Image Segmentation Techniques | Subhrajyoty Roy</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    
    
      <a class="navbar-brand" href="/">Subhrajyoty Roy</a>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Bio</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#accomplishments"><span>Accolades</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      

      

    </ul>

  </div>
</nav>


  <article class="article">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>An Introduction to Image Segmentation Techniques</h1>

  
  <p class="page-subtitle">During the time of shelter-in-place lockdown due to global pandemic of COVID-19</p>
  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Mar 23, 2020
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    20 min read
  </span>
  

  
  
  

  
  

</div>

  














</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 275px;">
  <div style="position: relative">
    <img src="/post/post5/featured_huc817a16a7aeaf5d55e143d0cb2e76621_664535_720x0_resize_lanczos_2.png" alt="" class="featured-image">
    <span class="article-header-caption"><a href="https://sites.google.com/site/highwaydrivingdataset/" target="_blank">The Highway Driving Database</a></span>
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      

<h2 id="a-lot-of-long-distance-good-luck">A lot of long distance Good Luck</h2>

<p>Currently, as I am writing this, it is a global pandemic situation all over the world, with a newly infectious disease caused by a newly discovered coronavirus, called COVID-19. According to the website to <a href="https://www.who.int/health-topics/coronavirus" target="_blank">WHO (World Health Organization)</a>, most people infected with the COVID-19 virus will experience mild to moderate respiratory illness and recover without requiring special treatment.  Older people, and those with underlying medical problems like cardiovascular disease, diabetes, chronic respiratory disease, and cancer are more likely to develop serious illness.</p>

<p>There are about 13 thousands people we have lost to the adverse effect of the disease, and more than three hundred thousands persons currently fighting against this disease, which rapidly grew out of China just within last three to four months. People are currently comparing it to the <a href="https://en.wikipedia.org/wiki/Spanish_flu" target="_blank">Spanish flu</a>, which took place roughly $100$ years before, and hence, almost none of us have any experience of dealing with a pandemic at such a large scale. As a countermeasure to reduce the spread of infectious disease, my hometown is at a Shelter-in-place lockdown, and hence I have almost nothing to do except scrapping through the internet to learn some new things that interests me.</p>

<p>However, I sincerely wish you all to stay unite, and stay safe. We would get through the hard times.</p>

<p><strong>WHO Guidelines to STAY SAFE:</strong></p>

<ul>
<li>The best way to prevent and slow down transmission is be well informed about the COVID-19 virus, the disease it causes and how it spreads.</li>
<li>Wash your hands frequently with an alcohol based rub or soap.</li>
<li>Maintain social distancing.</li>
<li>Avoid touching eyes, nose and mouth.</li>
<li>Practice respiratory hygiene.</li>
<li>If you have fever, cough and difficulty breathing, seek medical care early.</li>
<li>Stay informed and follow advice given by your healthcare provider.</li>
<li>Protect yourselves and protect others.</li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>Now, as you have quite guessed from the title of the post, this is about segmenting an image about different regions. Image Segmentation refers to the task that is used to seperate foreground from the background of an image. Before understanding what it means, note that, an image can be described as a collection of geometric shapes (lines, curves, polygons etc.) having various aesthestics mapping to real life (or fictional) quantities or objects. I find it essentially similar to that of <code>ggplot</code> plotting technique, we have a dataset comprising of some measurements or objects which we want to measure, and we can build a plot (read an image) out of it, by creating an aesthestic mapping of those measurements to geometric objects such as points, lines, curves, polygons etc. The book written by Leland Wilkinson named <a href="https://books.google.co.in/books/about/The_Grammar_of_Graphics.html?id=ZiwLCAAAQBAJ&amp;source=kp_book_description&amp;redir_esc=y" target="_blank"><strong>The Grammar of Graphics</strong></a> is one such book which describes the process in great detail.</p>

<p>Let me start with an example. Let&rsquo;s say you have an image of a red chair, with a white wall at the back. Now, when you look at the image, you are seeing possibly some polygons (which may have some curved edges), which defines different regions of a chair, each having a slightly different shade of colour, due to disparate reflective nature and absorption of photons when there is a lighting source used to illuminate the scene. Now, in simple terms, there is a latent dataset with rich measurements of different characteristics of the objects in the scene (namely the chair and the wall), namely containing the spatial and lighting informations, however we do not get to observe that.</p>

<table>
<thead>
<tr>
<th>x coordinate</th>
<th>y coordinate</th>
<th>z coordinate</th>
<th>colour(rgb)</th>
</tr>
</thead>

<tbody>
<tr>
<td>2.2123</td>
<td>23.443</td>
<td>0. 1768</td>
<td>(240, 75, 90)</td>
</tr>

<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>

<p>Now, an image can also be described as a mapping of the above rows to a rows like this (which is observable by means of the image at hand),</p>

<table>
<thead>
<tr>
<th>x coordinate</th>
<th>y coordinate</th>
<th>colour(rgb)</th>
</tr>
</thead>

<tbody>
<tr>
<td>23</td>
<td>35</td>
<td>(240, 75, 90)</td>
</tr>

<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>

<p>where the new x and y coordinates are coordinates in the 2-dimensional map described by the plane of the image. Now, to each of the rows of the latent dataset, we associated an object (because that is how we interprete it), for instance, the rows which consitute the 3-dimensional spatial coordinates of the location of atoms of the chiar, are associated with the chair, and the rest, maybe associated with the floor and the white wall. Image segmentation specifically refers to generating that interpretation in a systematic and automatic way, just by looking at the visual sensory information (i.e. the 2nd type of dataset), and the problem is difficult, as the mapping by which the latent dataset converted to this, is extremely complicated in nature (maybe unknown). Therefore, a perfect image segmentation achieves the hidden representation of an image into something that is more meaningful and easier to analyze.</p>

<h2 id="importing-necessary-python-packages">Importing Necessary Python Packages</h2>

<p>For this, we shall be using <code>numpy</code> for vector and matrix manipulations, <code>cv2</code>to read image files as a numpy array, and finally <code>matplotlib</code> for various plotting related tasks. I am using python 3.7.4 for this.</p>

<p><em>Note: If you want to know an image can be represented in an array (or a tensor), go check out the section on &ldquo;Making some utlity functions&rdquo; on my other post on <a href="https://subroy13.github.io/post/post3/" target="_blank">Texture Networks</a></em></p>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt
import sys
sys.version
</code></pre>

<pre><code>'3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]'
</code></pre>

<p>I shall be using the beautiful picture of <a href="https://en.wikipedia.org/wiki/Mona_Lisa" target="_blank">Mona Lisa</a> by Leaonardo Da Vinci. I am not a connoisseur about aesthestics, but I appreciate the image from the point of view that it has a subject, and a background, two very clearly seperated item in the image.</p>

<pre><code class="language-python">bw_img = cv2.imread('./Mona_Lisa.jpg')  # read a black and white version
col_img = cv2.imread('./Mona_Lisa_color.jpg')   # and a color version

# since, cv2 reads in BGR format, we need to use RGB format for plotting
col_img = cv2.cvtColor(col_img, cv2.COLOR_BGR2RGB)

fig, plots = plt.subplots(1,2, figsize = (15, 10))     # subplot with 1 row, 2 columns

# subplot 1
plots[0].imshow(bw_img, cmap='gray')
plots[0].set_title('Black &amp; White')

# subplot 2
plots[1].imshow(col_img)
plots[1].set_title('Colored')
plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_5_0.png" alt="png" /></p>

<h2 id="histogram-thresholding">Histogram Thresholding</h2>

<p>Histogram thresholding is the most basic way of segmenting an image. It is fast, simple yet very effective. For instance, assume we have a grayscale image, where the foreground and background has different grayscale intensities. Let us say, we have the grayscale intensity $i$ ($0 \leq i \leq 255$), appearing $f_i$ times in the image (i.e. there are $f_i$ pixels with grayscale intensity level $i$), and $N$ is the total number of digital pixels in the image. Now, assume that, the background object has a mean intensity level $\mu_b$, and foreground has mean intensity level $\mu_f$. Then, we assume,</p>

<p>$$
I_{x, y} \sim
\begin{cases}
g(i_{x, y}; \mu_f) &amp; \text{if (x, y) pixel belongs to foreground} \\<br />
g(i_{x, y}; \mu_b) &amp; \text{if (x, y) pixel belongs to background} \\<br />
\end{cases}
$$</p>

<p>where $I_{x, y}$ is the intensity level at (x, y)-th pixel of the image, which is a random variable (and is taking value $i_{x, y}$) and follows a density $g(\cdot)$ whose location is specified by $\mu_f$ or $\mu_b$, based on whether the pixel corresponds to background object (the white wall) or the foreground object (the red chair).</p>

<pre><code class="language-python">plt.hist(bw_img.ravel(), bins = 255)
plt.title('Histogram of grayscale values of Mona Lisa Image')
plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_7_0.png" alt="png" /></p>

<p>As you can see, there are 3 clear regions in the histogram, which might indicates, there are 3 such segments possible, since it looks like the histogram comprises of mixture of 3 random variables.</p>

<ol>
<li>First component has a mean about at 5.</li>
<li>Second component shows a mode (or peak) about at 45.</li>
<li>Third component shows a mode at 130.</li>
</ol>

<p>So, we consider some thresholds, at 25 and 95. Now, we shall simply use these thresholds, and assign different values to all pixel intensities that are smaller than 25 to one value, all in between 25 and 95 to another value, and all pixels higher than 95 to another value. This should give us some possible segmentation, although not automatic, but is useful to gain insights and idea about the method.</p>

<p>The following function performs the segmentation given the values of the thresholds.</p>

<pre><code class="language-python">def segment(img, thresholds):
    bins = [0]    # these are used to binning the image
    for i in range(len(thresholds)):
        bins.append( thresholds[i] )
    bins.append(256)
    
    img = np.array(img)
    bins = np.array(bins)
    segment_bin = np.digitize(img, bins)
    return(bins[segment_bin] )    # return the segmented image&quot;
</code></pre>

<p>Now we apply the threshold 25, 95 and both to see which regions are being identified as foreground and backgrund for which thresholds.</p>

<pre><code class="language-python">thres1 = [25]
thres2 = [95]
thres3 = [25, 95]

fig, plots = plt.subplots(1,3, figsize = (15, 10))     # subplot with 1 row, 3 columns

# subplot 1
plots[0].imshow(segment(bw_img, thres1), cmap='gray')
plots[0].set_title('Segment with threshold = 25')

# subplot 2
plots[1].imshow(segment(bw_img, thres2), cmap='gray')
plots[1].set_title('Segment with threshold = 95')

# subplot 3
plots[2].imshow(segment(bw_img, thres3), cmap='gray')
plots[2].set_title('Segment with threshold = 25 &amp; 95')

plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_11_1.png" alt="png" /></p>

<p>It seems that, the threshold at 25 separates the clothings and darker shades of skin of Mona Lisa from the background, while threshold at 95 tend to separate the lighter shades of skin (the face, the hands). Combining both yields a good understanding of the different segments available in the image.</p>

<p>Now, let us perform similar analysis on the coloured version of the image. In that case, we process each of the channel seperately through this procedure.</p>

<pre><code class="language-python">fig, plots = plt.subplots(1,3, figsize = (15, 3))     # subplot with 1 row, 3 columns

# subplot 1
plots[0].hist(col_img[:,:,0].ravel(), bins = 255)
plots[0].set_title('Histogram of R channel')

# subplot 2
plots[1].hist(col_img[:,:,1].ravel(), bins = 255)
plots[1].set_title('Histogram of G channel')

# subplot 3
plots[2].hist(col_img[:,:,2].ravel(), bins = 255)
plots[2].set_title('Histogram of B channel')

plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_13_0.png" alt="png" /></p>

<p>Now, it seems a lot more difficult to separate background from foreground on the basis of thresholds just by subjectively judging them.</p>

<pre><code class="language-python">thres_R = [50, 100]
thres_G = [100]
thres_B = [55]

segment_R = np.expand_dims( segment(col_img[:, :, 0], thres_R) , 2)    # apply segmentation and convert to 3d array
segment_G = np.expand_dims( segment(col_img[:, :, 1], thres_G) , 2)
segment_B = np.expand_dims( segment(col_img[:, :, 2], thres_B) , 2)

segment_img = np.concatenate( (segment_R, segment_G, segment_B), axis = 2)


fig, plots = plt.subplots(1,4, figsize = (20, 5))     # subplot with 1 row, 4 columns

# subplot 1
plots[0].imshow(segment_R[:, :, 0], cmap = 'gray')
plots[0].set_title('Segmentation of R channel')

# subplot 2
plots[1].imshow(segment_G[:, :, 0], cmap = 'gray')
plots[1].set_title('Segmentation of G channel')

# subplot 3
plots[2].imshow(segment_B[:, :, 0], cmap = 'gray')
plots[2].set_title('Segmentation of B channel')

# final image
plots[3].imshow(segment_img)
plots[3].set_title('Final segmentation of image')

plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_15_1.png" alt="png" /></p>

<p>Therefore, we see that most the segmentation generally comes from the G channel itself, but the final segmentation does not look very promising. As you can see, there are lots of artifacts and noises all around. Therefore, we need our workaround against this, which we shall be discussing shortly.</p>

<h2 id="otsu-s-method">Otsu&rsquo;s Method</h2>

<p>Otsu&rsquo;s method is a automatic way of detecting such thresholds. To better understand it, consider a threshold value $s$. Then, the best estimate of $\mu_f$ and $\mu_b$ are as follows:</p>

<p>$$
\begin{align}
\mu_b^{(s)} &amp; = \dfrac{\sum_{i = 0}^{s} i f_i }{\sum_{i = 0}^{s} f_i}\\<br />
\mu_f^{(s)} &amp; = \dfrac{\sum_{i = (s+1)}^{255} i f_i }{\sum_{i = (s+1)}^{255} f_i}\\<br />
\end{align}
$$</p>

<p>where the superscript is used to denote the threshold $s$.</p>

<p>Assuming that, foreground has higher lower intensity level than the foreground (or object) due to the fact that object is properly illuminated, one way to choose the threshold that minimizes the weighted intraclass variance, or conversely maximize the weighted interclass variance. Now, the formula of weighted interclass variance is simply;</p>

<p>$$V = \dfrac{{\sum_{i = 0}^{s} f_i}}{N} \times \dfrac{{\sum_{i = 0}^{s} f_i}}{N} \times \left[ \mu_b^{(s)}  - \mu_f^{(s)}\right]^2$$</p>

<p>The following function computes this interclass variance for all threshold levels $s = 1, 2, \dots 254$.</p>

<pre><code class="language-python">def interclass_var(img):
    var = np.zeros(256)
    freq = np.zeros(256)
    
    # obtain f_i's
    for i in range(img.shape[0]):
        for j in range(img.shape[1]):
            freq[img[i, j]] += 1     # increase corresponding intensity frequency
            
    for s in range(1, 255):
        w1 = freq[0:s].sum()
        w2 = freq[s:].sum()
        if w1!=0 and w2!= 0:
            mu1 = sum( np.arange(s) * freq[0:s] ) / w1
            mu2 = sum( np.arange(s, 256) * freq[s:] ) / w2
            var[s] = w1 * w2 * ((mu1 - mu2)**2)
    
    return var
</code></pre>

<pre><code class="language-python">var = interclass_var(bw_img)
plt.plot(var)
plt.title(&quot;Otku's Interclass variation&quot;)
plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_18_0.png" alt="png" /></p>

<pre><code class="language-python">np.argmax(var)
</code></pre>

<pre><code>78
</code></pre>

<p>It seems that 78 is the proper threshold where the interclass variance is maximized. So, let us take a look how the segmentation is for only one threshold equal to 78.</p>

<pre><code class="language-python">thres = [78]

fig, plots = plt.subplots(1,2, figsize = (10, 5))     # subplot with 1 row, 2 columns

# subplot 1
plots[0].imshow(bw_img, cmap='gray')
plots[0].set_title('Original Image')

# subplot 2
plots[1].imshow(segment(bw_img, thres), cmap='gray')
plots[1].set_title('Segment with threshold = 78')

plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_21_1.png" alt="png" /></p>

<p>We see that, the segmentation looks pretty good for just two shades of gray. However, it would have been better if the background was given a different shade from <a href="https://en.wikipedia.org/wiki/Lisa_del_Giocondo" target="_blank">Lisa del Giocondo</a>, the possible model for Mona Lisa. However, since in the original picture, they both have similar shades of gray, we cannot do it just based on the histogram of colour intensities. So, we need to account for spatial information as well.</p>

<p>Let us see, how much this automatic thresholding give us in the colour image of Mona Lisa.</p>

<pre><code class="language-python">var_r = interclass_var(col_img[:, :, 0])
var_g = interclass_var(col_img[:, :, 1])
var_b = interclass_var(col_img[:, :, 2])

print('Threshold for R channel', np.argmax(var_r))
print('Threshold for G channel', np.argmax(var_g))
print('Threshold for B channel', np.argmax(var_b))
</code></pre>

<pre><code>Threshold for R channel 94
Threshold for G channel 82
Threshold for B channel 61
</code></pre>

<pre><code class="language-python"># Exactly same code as before
thres_R = [94]
thres_G = [82]
thres_B = [61]

segment_R = np.expand_dims( segment(col_img[:, :, 0], thres_R) , 2)    # apply segmentation and convert to 3d array
segment_G = np.expand_dims( segment(col_img[:, :, 1], thres_G) , 2)
segment_B = np.expand_dims( segment(col_img[:, :, 2], thres_B) , 2)

segment_img = np.concatenate( (segment_R, segment_G, segment_B), axis = 2)

fig, plots = plt.subplots(1,4, figsize = (20, 5))     # subplot with 1 row, 4 columns

# subplot 1
plots[0].imshow(segment_R[:, :, 0], cmap = 'gray')
plots[0].set_title('Segmentation of R channel')

# subplot 2
plots[1].imshow(segment_G[:, :, 0], cmap = 'gray')
plots[1].set_title('Segmentation of G channel')

# subplot 3
plots[2].imshow(segment_B[:, :, 0], cmap = 'gray')
plots[2].set_title('Segmentation of B channel')

# final image
plots[3].imshow(segment_img)
plots[3].set_title('Final segmentation of image')

plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_24_1.png" alt="png" /></p>

<p>The final segmentation clearly segments all the regions, like background and the model. However, it is extremely noisy. So, otsu&rsquo;s automatic thresholding does not perform any better for colour images.</p>

<h2 id="incorporating-spatial-information-co-occurence-matrix">Incorporating Spatial Information: Co-occurence Matrix</h2>

<p>To incorporate spatial information, as well as consider the intensity values of the image, there is a popular notion of Co-occurence matrix. As the name suggests, it captures how many times two intensity levels $i$ and $j$ appear spatially together in the image, and put that frequency in $(i, j)$-th cell of the matrix.</p>

<p>For example, the $(a, b)$-th entry of the co-occurence matrix is the frequency of the number of times, when $a$ appears at a pixel location of the image, and the color $b$ appears at the specified offset from that pixel locations. Now, if the offset is set to be $(1, 0)$, then it means the number of times the pixel intensities $(a, b)$ appear side by side horizontally in this order is given by the $(a, b)$-th element of the co-occurence matrix.</p>

<p>So, let us create a function which computes the co-occurence matrix for us.</p>

<pre><code class="language-python"># Create co-occurence matrix
def CCM(img, offset):
    comat = np.zeros((256, 256))
    for i in range(img.shape[0] - offset[0]):
        for j in range(img.shape[1] - offset[1]):
            comat[img[i, j], img[i + offset[0], j + offset[1]] ] += 1
    return(comat)
</code></pre>

<p>Now that we have our co-occurence matrix, consider a specified threshold $s$. Then, the $256\times 256$ order co-occurence matrix can be partitioned into $4$ parts as follows;</p>

<p>$$
\begin{bmatrix}
A &amp; B\\<br />
C &amp; D
\end{bmatrix}
$$</p>

<p>where $A$ is of order $s \times s$. Let, $a, b, c, d$ denotes the sum of the entries in partioned regions $A, B, C, D$ respectively. Clearly, if the threshold is selected as such so that background and foreground can be broken up nicely, then it means, the entries of $B$ and $C$ are going to be small. Since, they represent the number of times a background color changes to foreground color and vice-versa. Armed with this knowledge, two very simple measures we can propose.</p>

<p>$$m_1 = \dfrac{b+c}{a + b + c + d}$$</p>

<p>and another based on conditional probability;</p>

<p>$$m_2 = \dfrac{1}{2} \left( \dfrac{b}{a+b} + \dfrac{c}{c+d} \right)$$</p>

<p>Minimizing these disparity measures with respect to the choice of $s$, should give us a reasonably good segmentation.</p>

<pre><code class="language-python">def discre_measure(comat, s):
    a = comat[0:s, 0:s].sum()
    b = comat[0:s, s:].sum()
    c = comat[s:, 0:s].sum()
    d = comat[s:, s:].sum()
    
    m1 = (b + c)/(a + b + c + d)
    m2 = ((b / (a + b)) + (c / (c + d)) )/2
    
    return((m1, m2))
</code></pre>

<pre><code class="language-python">T_h = CCM(bw_img, offset = (0, 1))   # consider horizontal offset
T_v = CCM(bw_img, offset = (1, 0))   # consider vertical offset
T_hv = T_h + T_v   # sum to obtain a good spatially informed co-occurence like matrix
</code></pre>

<p>Now we compute these measures for all thresholds from $0$ to $255$, and then plot their graphs in order to find the minimum of the objective function (or the measure)</p>

<pre><code class="language-python">scores_m1 = []
scores_m2 = []

for s in range(1, 255):
    score = discre_measure(T_hv, s)
    scores_m1.append( score[0] )
    scores_m2.append( score[1] )
    
fig, plots = plt.subplots(1,2, figsize = (20, 5))     # subplot with 1 row, 2 columns

# subplot 1
plots[0].plot(scores_m1)
plots[0].set_title('Measure 1')

# subplot 2
plots[1].plot(scores_m2)
plots[1].set_title('Measure 2')
plots[1].set_ylim([0, 0.1])

plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_31_1.png" alt="png" /></p>

<p>Now, there are several local minimas. Note that, using a global rule for obtaining the minimum value would possibly lead to a poor segmentation. Hence, we apply a moving window through the array of these scores, to find a value which is minimum in a window span of length $2K$, where $K$ is a choice by the user. Clearly, higher values of $K$ will lead to smaller number of segments, and lower values of $K$ will give higher number of segments. This moving minimum algorithm is implemented in the following piece of code.</p>

<pre><code class="language-python">def find_min(scores, k = 1):
    thresholds = []
    for i in range(k, len(scores) - k):
        if min(scores[(i-k):(i+k)]) == scores[i]:
            thresholds.append(i)
    return(thresholds)
</code></pre>

<p>Now, we consider the images segmentation for $k = 1, 3, 5, 10, 20$, firstly for Measure 1 and then for Measure 2.</p>

<pre><code class="language-python">fig, plots = plt.subplots(1,5, figsize = (20, 5))     # subplot with 1 row, 5 columns

# subplot 1
plots[0].imshow( segment(bw_img, find_min(scores_m1, k = 1)) , cmap = 'gray')
plots[0].set_title('k = 1 ( Measure 1 )')

# subplot 2
plots[1].imshow( segment(bw_img, find_min(scores_m1, k = 3)) , cmap = 'gray')
plots[1].set_title('k = 3 ( Measure 1 )')

# subplot 3
plots[2].imshow( segment(bw_img, find_min(scores_m1, k = 5)) , cmap = 'gray')
plots[2].set_title('k = 5 ( Measure 1 )')

# subplot 4
plots[3].imshow( segment(bw_img, find_min(scores_m1, k = 10)) , cmap = 'gray')
plots[3].set_title('k = 10 ( Measure 1 )')

# subplot 4
plots[4].imshow( segment(bw_img, find_min(scores_m1, k = 20)) , cmap = 'gray')
plots[4].set_title('k = 20 ( Measure 1 )')


plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_35_0.png" alt="png" /></p>

<pre><code class="language-python">fig, plots = plt.subplots(1,5, figsize = (20, 5))     # subplot with 1 row, 5 columns

# subplot 1
plots[0].imshow( segment(bw_img, find_min(scores_m2, k = 1)) , cmap = 'gray')
plots[0].set_title('k = 1 ( Measure 2 )')

# subplot 2
plots[1].imshow( segment(bw_img, find_min(scores_m2, k = 3)) , cmap = 'gray')
plots[1].set_title('k = 3 ( Measure 2 )')

# subplot 3
plots[2].imshow( segment(bw_img, find_min(scores_m2, k = 5)) , cmap = 'gray')
plots[2].set_title('k = 5 ( Measure 2 )')

# subplot 4
plots[3].imshow( segment(bw_img, find_min(scores_m2, k = 10)) , cmap = 'gray')
plots[3].set_title('k = 10 ( Measure 2 )')

# subplot 4
plots[4].imshow( segment(bw_img, find_min(scores_m2, k = 20)) , cmap = 'gray')
plots[4].set_title('k = 20 ( Measure 2 )')


plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_36_1.png" alt="png" /></p>

<p>It looks like for $k = 10$, with measure 1 and for $k = 20$ with meausre 2, we have similar kind of segmentation of the image. However, with measure 2, $k = 20$, the segmentation looks much clearer and ideal, as there are light noises to the background, and almost no noises in definiting the edge of the clothings of the model from the background.</p>

<p>Now, let us inspect how does the thresholds found by this algorithm maps to the co-occurence matrix.</p>

<pre><code class="language-python">cutoffs1 = np.array(find_min(scores_m1, k = 10))
cutoffs2 = np.array(find_min(scores_m2, k = 20))

fig, plots = plt.subplots(1, 2, figsize = (20, 5))     # subplot with 1 row, 2 columns

# subplot 1
a = plots[0].imshow(np.log(T_hv))   # take logarithm for ease of visualization
fig.colorbar(a, ax = plots[0])
for cut in cutoffs1:
    plots[0].plot( [cut, cut], [255, 0] , &quot;r-&quot;)
    plots[0].plot( [255, 0], [cut, cut], &quot;r-&quot;)

# subplot 2
b = plots[1].imshow(np.log(T_hv))   # take logarithm for ease of visualization
fig.colorbar(b, ax = plots[1])
for cut in cutoffs2:
    plots[1].plot( [cut, cut], [255, 0] , &quot;r-&quot;)
    plots[1].plot( [255, 0], [cut, cut], &quot;r-&quot;)

plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_38_1.png" alt="png" /></p>

<p>As you can see, there are lots of unnecessary thresholds selected for measure1. However, then two principal thresholds selected by these methods are at about $25$ and at about $95$, which were the thresholds we picked at the very beginning just by looking at the thresholds. Even with the very basic tool such a histogram, and a little subjective evaluation, we could achieve a reasonable amount of segmentation.</p>

<p>Now, let us try to apply this method on the colour image as well.</p>

<pre><code class="language-python">T_hv_red = CCM(col_img[:, :, 0], offset = (0, 1)) + CCM(col_img[:, :, 0], offset = (1, 0))
T_hv_green = CCM(col_img[:, :, 1], offset = (0, 1)) + CCM(col_img[:, :, 1], offset = (1, 0))
T_hv_blue = CCM(col_img[:, :, 2], offset = (0, 1)) + CCM(col_img[:, :, 2], offset = (1, 0))
</code></pre>

<pre><code class="language-python">scores_m1 = np.zeros((3, 256))
scores_m2 = np.zeros((3, 256))

for s in range(1, 255):
    score_red = discre_measure(T_hv_red, s)
    score_green = discre_measure(T_hv_green, s)
    score_blue = discre_measure(T_hv_blue, s)
    
    scores_m1[:, s] =  (score_red[0], score_green[0], score_blue[0])
    scores_m2[:, s] =  (score_red[1], score_green[1], score_blue[1])
</code></pre>

<pre><code class="language-python">fig, plots = plt.subplots(1, 2, figsize = (20, 5))     # subplot with 1 row, 2 columns

# subplot 1
plots[0].plot(scores_m1[0, :], c = 'r')
plots[0].plot(scores_m1[1, :], c = 'g')
plots[0].plot(scores_m1[2, :], c = 'b')
plots[0].set_title('Measure 1')

# subplot 2
plots[1].plot(scores_m2[0, :], c = 'r')
plots[1].plot(scores_m2[1, :], c = 'g')
plots[1].plot(scores_m2[2, :], c = 'b')
plots[1].set_title('Measure 2')

plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_42_0.png" alt="png" /></p>

<p>Note that, for Red and Blue channel, the 2nd measure gives prominent minimums, while for the  Green channel, the prominent minima is obtained by the first measure. Therefore, with some custom tweaking of $K$ and the which measure to choose, you can get a segmentation which is better than methods discussed previously, just because it uses the spatial information, which connects these three channels together.</p>

<pre><code class="language-python"># Exactly same code as before
thres_R = find_min(scores_m2[0, :], k = 30)
thres_G = find_min(scores_m1[1, :], k = 25)
thres_B = find_min(scores_m2[2, :], k = 10)

segment_R = np.expand_dims( segment(col_img[:, :, 0], thres_R) , 2)    # apply segmentation and convert to 3d array
segment_G = np.expand_dims( segment(col_img[:, :, 1], thres_G) , 2)
segment_B = np.expand_dims( segment(col_img[:, :, 2], thres_B) , 2)

segment_img = np.concatenate( (segment_R, segment_G, segment_B), axis = 2)

fig, plots = plt.subplots(1,4, figsize = (20, 5))     # subplot with 1 row, 4 columns

# subplot 1
plots[0].imshow(segment_R[:, :, 0], cmap = 'gray')
plots[0].set_title('Segmentation of R channel')

# subplot 2
plots[1].imshow(segment_G[:, :, 0], cmap = 'gray')
plots[1].set_title('Segmentation of G channel')

# subplot 3
plots[2].imshow(segment_B[:, :, 0], cmap = 'gray')
plots[2].set_title('Segmentation of B channel')

# final image
plots[3].imshow(segment_img)
plots[3].set_title('Final segmentation of image')

plt.show()
</code></pre>

<p><img src="./Image%20Segmentation%20Techniques_44_1.png" alt="png" /></p>

<p>As it seems, the final segmented image looks better than the previous ones. Note that,</p>

<ul>
<li>The sky is coloured green, (since the green channel was able to capture that properly)</li>
<li>The visible first layer of background, which is the valley, is coloured blue, as blue channel properly captures that.</li>
<li>The visible second layer of background, which constitutes what is possibly iceberg (or some rivers) is captures in the red channel (and hence is of brown colour in the final segmentation).</li>
<li>The skin of Mona Lisa is capture in red and green channel, and slightly by blue channel, which mixes up to give a different tone for the skin.</li>
<li>The dark clothing is not captured through any of the channel segmentation, hence remains dark in the final outcome.</li>
</ul>

<p>The following are some references if you wish to boost up your knowledge and learn subtle details of the algorithms presented above.</p>

<h2 id="references">References</h2>

<ol>
<li><p>F. Deravi and S.K. Pal, &ldquo;Gray Level Thresholding Using Second-order Statistics&rdquo;, Pattern Recogn. Letters, vol. 1, pp.417-422, 1983. <a href="https://www.isical.ac.in/~sankar/paper/pdf21.pdf" target="_blank">PDF</a>.</p></li>

<li><p><a href="https://en.wikipedia.org/wiki/Thresholding_(image_processing)" target="_blank">Wikipedia article Thresholding (image processing).</a></p></li>

<li><p><a href="https://en.wikipedia.org/wiki/Otsu%27s_method" target="_blank">Wikipedia article Otsu&rsquo;s Method</a></p></li>

<li><p><a href="https://en.wikipedia.org/wiki/Image_segmentation" target="_blank">Wikipedia article Image Segmentation</a></p></li>

<li><p>Linda G. Shapiro and George C. Stockman (2001): “Computer Vision”, pp 279-325, New Jersey, Prentice-Hall, ISBN 0-13-030796-3 <a href="http://nana.lecturer.pens.ac.id/index_files/referensi/computer_vision/Computer%20Vision.pdf" target="_blank">PDF</a></p></li>
</ol>

<p><strong>Note:</strong> <em>The model, Lisa del Giocondo, was a member of the Gherardini family of Florence and Tuscany, and the wife of wealthy Florentine silk merchant Francesco del Giocondo. The Italian name for the painting, La Gioconda, means &lsquo;jocund&rsquo; (&lsquo;happy&rsquo; or &lsquo;jovial&rsquo;) or, literally, &lsquo;the jocund one&rsquo;, a pun on the feminine form of Lisa&rsquo;s married name, Giocondo. In French, the title La Joconde has the same meaning, i.e. to become happy. ~ Wikipedia</em></p>

<p>&amp; Finally, stay safe and keep safe your families, friends and neighbours!</p>

    </div>

    







<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/post/post5/&amp;text=An%20Introduction%20to%20Image%20Segmentation%20Techniques" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/post/post5/&amp;t=An%20Introduction%20to%20Image%20Segmentation%20Techniques" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=An%20Introduction%20to%20Image%20Segmentation%20Techniques&amp;body=/post/post5/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/post/post5/&amp;title=An%20Introduction%20to%20Image%20Segmentation%20Techniques" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=An%20Introduction%20to%20Image%20Segmentation%20Techniques%20/post/post5/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/post/post5/&amp;title=An%20Introduction%20to%20Image%20Segmentation%20Techniques" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  






  
  
  
    
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_huf5179412b91fcd36fa0e64dc821bb1a0_472198_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/">Subhrajyoty Roy</a></h5>
      <h6 class="card-subtitle">Student at Master of Statistics</h6>
      <p class="card-text">My research interests include Applied Statistics in economical, financial and computational fields, Machine Learning, Deep learning and Data Visualization techniques.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/subroy13" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>







<div class="article-widget">
  
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/post/post4/" rel="prev">Intuitive Introduction to Differential Geometry</a>
  </div>
  
</div>

</div>



  
  



  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.3.1/mermaid.min.js" integrity="sha256-vOIuDSYDirTfyr+S2MjFnhOz6Rgiz4ODFAHATG0rFxw=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/python.min.js"></script>
        
      

      
      
      <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.0e040a4c8b8532fc173c2fe4328906d0.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms</a>
    
  </p>
  

  <p class="powered-by">
    &copy; All rights reserved for contents only, 2019 &middot; 
    
    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
